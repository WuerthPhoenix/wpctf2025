{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f5f481",
   "metadata": {},
   "source": [
    "# Challenge solution\n",
    "\n",
    "The goal of this notebook is to provide an example solution to the challenge `Choosing the right words`.\n",
    "\n",
    "The following method is inspired by the method proposed in the paper [Adversarial_Attacks_Against_Machine_Learning_Based_SpamFilters](https://isi.jhu.edu/wp-content/uploads/2022/04/Adversarial_Attacks_Against_Machine_Learning_Based_SpamFilters__IEEE.pdf). \n",
    "\n",
    "However, it does not follow it completely and was modified to actually perform a \"good words\" attack using only spam emails. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e4f6b",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We start by importing the libraries used, mainly scikit-learn and pandas, plus requests to submit automatically the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a029e7",
   "metadata": {},
   "source": [
    "We then define the target host of the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE_HOST = 'http://localhost:8000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611d386",
   "metadata": {},
   "source": [
    "We then define the two functions used to perform a projcted gradient attack and desume then the best words that we can then use to trick the classifier. \n",
    "\n",
    "The main idea is the following: \n",
    "- The function `pgd_attack` performs the projected gradient attack. The steps are the following:\n",
    "    - It re-uses the model to compute the TF-IDF representation of the target emails and then scales the feature using the MinMax scaler, to ensure large features values \n",
    "      do not influence the prediction more than they should.\n",
    "    - It extracts some random examples from the spam emails to perform the attack\n",
    "    - For each of the extracted examples: \n",
    "      - Copies the original features\n",
    "      - Applies the model (the weights have been extracted previously) and computes the gradient\n",
    "      - Performs a step in the direction of the gradient\n",
    "    - All successful attacks are then stored\n",
    "- The function `the_right_words` maps the perturbed TF-IDF representations back to words. It does as follows: \n",
    "  - Computes the average perturbation per word, meaning how much they were changed on average during our attacks\n",
    "  - Combines this with the model coefficient (aka how much the model relies on them) to get a combined score of perturbation * importance\n",
    "  - Extract back the feature names and sorts them by importance\n",
    "  - Filters out words that were not changed or that have a super large weigth, to find subtle words\n",
    "  - Intersect the words with the ones present in the spam emails and returns them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588815b9",
   "metadata": {},
   "source": [
    "**TLDR; The idea of the attack:**: the main idea is to perform a sort of adversarial attack but not on the email itself but on the distribution of words (TF-IDF representation) to understand which words were understood by the model to be \"ham\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0eeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(\n",
    "    clf_pipeline,\n",
    "    X,\n",
    "    nb_attack=20,\n",
    "    dmax=1.0,\n",
    "    step_size=0.1,\n",
    "    max_iter=100\n",
    "):\n",
    "    # Exctract components from the pipeline\n",
    "    tf_idf_transformer = clf_pipeline.named_steps['tfidfvectorizer']\n",
    "    scaler = clf_pipeline.named_steps['maxabsscaler']\n",
    "    clf = clf_pipeline.named_steps['sgdclassifier']\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_tfidf = tf_idf_transformer.transform(X)\n",
    "    X_scaled = scaler.transform(X_tfidf)\n",
    "\n",
    "    # Get model parameters\n",
    "    w = clf.coef_[0]\n",
    "    b = clf.intercept_[0]\n",
    "\n",
    "    # Randomly select samples to attack\n",
    "    selected_idxs = np.random.choice(X.shape[0], size=nb_attack, replace=False)\n",
    "\n",
    "    successes = 0\n",
    "    results = []\n",
    "\n",
    "    # Perform PGD attack\n",
    "    for i in selected_idxs:\n",
    "        x0 = X_scaled[i].toarray().flatten()\n",
    "        y0 = 1\n",
    "        x_adv = x0.copy()\n",
    "\n",
    "        # PGD iterations\n",
    "        for it in range(max_iter):\n",
    "            # Compute gradient\n",
    "            margin_raw = np.dot(w, x_adv.T) + b\n",
    "            sigmoid = 1 / (1 + np.exp(-y0 * margin_raw))\n",
    "            grad = (sigmoid - 1) * (-y0 * w)\n",
    "            \n",
    "            # Gradient step\n",
    "            x_adv = x_adv - step_size * grad\n",
    "\n",
    "            # Project to L2 ball\n",
    "            delta = x_adv - x0\n",
    "            norm = np.linalg.norm(delta, ord=2)\n",
    "\n",
    "            # If outside the ball, project back\n",
    "            if norm > dmax:\n",
    "                delta = delta / norm * dmax\n",
    "                x_adv = x0 + delta\n",
    "\n",
    "            # Clip to valid range\n",
    "            x_adv = np.clip(x_adv, 0.0, 1.0)\n",
    "\n",
    "        # Check if attack was successful\n",
    "        pred_scaled = clf.predict([x_adv])[0]\n",
    "\n",
    "        score_orig = np.dot(w, x0) + b\n",
    "        score_adv = np.dot(w, x_adv) + b\n",
    "        print(f\"Margin: {score_orig:.4f} â†’ {score_adv:.4f}\")\n",
    "        print(f\"Original: 1 -> Adv: {pred_scaled}\")\n",
    "\n",
    "        # If attack was successful, log the results\n",
    "        if pred_scaled != 1:\n",
    "            successes += 1\n",
    "            delta_tfidf = scaler.inverse_transform(x_adv.reshape(1, -1)) - scaler.inverse_transform(x0.reshape(1, -1))\n",
    "            results.append(delta_tfidf.flatten())\n",
    "\n",
    "\n",
    "    print(f\"Total attacks: {nb_attack}, Successful attacks: {successes}\")\n",
    "    print(f\"PGD attack success rate: {successes / nb_attack:.2f}\")\n",
    "\n",
    "    return np.vstack(results), successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671103c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_right_words(\n",
    "    clf, \n",
    "    x_val,\n",
    "    result\n",
    "):\n",
    "    # Ensure result is a NumPy array\n",
    "    result_array = np.array(result)\n",
    "    coef = clf.named_steps['sgdclassifier'].coef_[0]\n",
    "\n",
    "    # Square the perturbation magnitudes (L2-style)\n",
    "    avg_perturb = np.mean(result_array ** 2, axis=0) \n",
    "\n",
    "    # 3. Compute importance based on direction\n",
    "    importance = avg_perturb * coef\n",
    "\n",
    "    tf_idf_transformer = clf.named_steps['tfidfvectorizer']\n",
    "\n",
    "    # Get the correct feature names from the training vectorizer\n",
    "    feature_names = tf_idf_transformer.get_feature_names_out()\n",
    "\n",
    "    # 4. Build DataFrame\n",
    "    average_importance_df = pd.DataFrame({\n",
    "        'word': feature_names,\n",
    "        'coef': coef,\n",
    "        'perturb': avg_perturb,\n",
    "        'importance': importance\n",
    "    })\n",
    "\n",
    "    # Filter out unimportant features\n",
    "    average_importance_df = average_importance_df[average_importance_df['coef'] < 0.2]\n",
    "    average_importance_df = average_importance_df[average_importance_df['perturb'] > 0]\n",
    "    average_importance_df = average_importance_df[average_importance_df['word'].str.count(' ') == 0]\n",
    "\n",
    "    # Sort and extract top features\n",
    "    sorted_features = average_importance_df.sort_values(by='importance', ascending=True)\n",
    "    important_features = sorted_features['word'].head(100).tolist()\n",
    "\n",
    "    # Create a DataFrame from validation data\n",
    "    val_data = pd.DataFrame({'message': x_val, 'label': 1})\n",
    "\n",
    "    # Fit TF-IDF vectorizers to spam messages\n",
    "    tfidf_vectorizer_spam = TfidfVectorizer()\n",
    "    tfidf_vectorizer_spam.fit(val_data['message'])\n",
    "    spam_feature_names = tfidf_vectorizer_spam.get_feature_names_out()\n",
    "\n",
    "    # Find intersection of unique spam words and important features (the ones that push towards ham)\n",
    "    ham_words_in_important_features = list(set(spam_feature_names).intersection(set(important_features)))\n",
    "    ham_words_str = \" \".join(ham_words_in_important_features)\n",
    "\n",
    "\n",
    "    return ham_words_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ced644",
   "metadata": {},
   "source": [
    "We then read the spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../challenge/spam_emails.csv')\n",
    "x = df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c4462",
   "metadata": {},
   "source": [
    "And the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7521952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model\n",
    "import skops.io as sio\n",
    "\n",
    "clf = sio.load('../challenge/model.skops')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ec892",
   "metadata": {},
   "source": [
    "Perform the PGD attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, successes = pgd_attack(\n",
    "    clf,\n",
    "    x,\n",
    "    nb_attack=100,\n",
    "    dmax=10.0,\n",
    "    step_size=0.5,\n",
    "    max_iter=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffdddb8",
   "metadata": {},
   "source": [
    "Identifies the words that we can use to alter the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_right_words = the_right_words(clf, x, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300ff6e",
   "metadata": {},
   "source": [
    "Prints them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identified right words:\", identified_right_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf73b2",
   "metadata": {},
   "source": [
    "Send the top 30 to the endpoint expose by the challenge and prints the result (the flag)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95dd3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(f'{CHALLENGE_HOST}/some-ancient-words', json={'sentence': \" \".join(identified_right_words.split()[:30])})\n",
    "print(res.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
